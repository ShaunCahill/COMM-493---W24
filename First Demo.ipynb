{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cf059e80-598c-4b81-9dbc-57297c487aa3",
   "metadata": {},
   "source": [
    "![](COMM_493_Banner.png)\n",
    "\n",
    "# This is a Jupyter Notebook\n",
    "\n",
    "This is where you will develop the \"Business\" part of your assignments.\n",
    "\n",
    "You can createâ€¦\n",
    "\n",
    "\n",
    "**Headings**\n",
    "\n",
    "# Heading 1\n",
    "\n",
    "## Header 2\n",
    "\n",
    "### Heading 3\n",
    "\n",
    "\n",
    "**Lists**\n",
    "\n",
    "1. One\n",
    "2. Two\n",
    "3. Three\n",
    "\n",
    "\n",
    "[Markdown Cheatsheet](https://github.com/adam-p/markdown-here/wiki/Markdown-Cheatsheet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26ac78d1-9e5b-4a34-8e89-da316387102f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# You can also run code\n",
    "print(\"Hello World\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58afe7a5-5961-4753-bda8-460acaf52d42",
   "metadata": {},
   "source": [
    "# We will be using the folowing libraries throughout this course"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feb3ab4e-9f3b-4d5b-adcb-6762c72080aa",
   "metadata": {},
   "source": [
    "![](NumPy.png)\n",
    "\n",
    "NumPy can be used to perform a wide variety of mathematical operations on arrays. It adds powerful data structures to Python that guarantee efficient calculations with arrays and matrices and it supplies an enormous library of high-level mathematical functions that operate on these arrays and matrices.\n",
    "\n",
    "**Why use NumPy**\n",
    "\n",
    "NumPy arrays are faster and more compact than Python lists. An array consumes less memory and is convenient to use. NumPy uses much less memory to store data and it provides a mechanism of specifying the data types. This allows the code to be optimized even further.\n",
    "\n",
    "[NumPy Documentation](https://numpy.org/devdocs/index.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1734931-c933-466d-a2b0-dfbeb911d037",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Comment these lines for students to be able to learn.\n",
    "\n",
    "# Define a Python list named 'a' with some integers.\n",
    "a = [1, 2, 3, 4, 5]\n",
    "\n",
    "# Print the contents of the list 'a'.\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09774297-84c1-4dd2-b3e2-d5567a95c2b6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Import the NumPy library and alias it as 'np'\n",
    "import numpy as np\n",
    "\n",
    "# Create a NumPy array 'b' with some integers\n",
    "b = np.array([1, 2, 3, 4, 5])\n",
    "\n",
    "# Print the contents of the NumPy array 'b'\n",
    "print(b)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd5e0587-5eea-4184-821f-de98a765b7c2",
   "metadata": {},
   "source": [
    "Not that exciting is it?  It will be when we start dealing with larger datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8984e27-c1ee-4289-8506-4be219d62e94",
   "metadata": {},
   "source": [
    "![](matplotlib_logo.png)\n",
    "\n",
    "# Matplotlib: Visualization with Python\n",
    "\n",
    "Matplotlib is a comprehensive library for creating static, animated, and interactive visualizations in Python. Matplotlib makes easy things easy and hard things possible.\n",
    "\n",
    "* Create publication quality plots.\n",
    "* Make interactive figures that can zoom, pan, update.\n",
    "* Customize visual style and layout.\n",
    "* Export to many file formats.\n",
    "* Embed in JupyterLab and Graphical User Interfaces.\n",
    "* Use a rich array of third-party packages built on Matplotlib.\n",
    "\n",
    "[matplotlib Documentation](https://matplotlib.org/stable/index.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f3dff43-28d2-49c9-88f6-5c1f8c8ebc9c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create a simple line plot with only y data\n",
    "plt.plot([1, 2, 3, 4])\n",
    "\n",
    "# Add a label to the Y-axis\n",
    "plt.ylabel('some numbers')\n",
    "\n",
    "# Display the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e42bc899-1c26-4833-a432-11114454bc83",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create a simple line plot with x and y data\n",
    "plt.plot([1, 2, 3, 4], [1, 4, 9, 16])\n",
    "\n",
    "# Add a label to the Y-axis\n",
    "plt.ylabel('Y Axis Numbers')\n",
    "\n",
    "# Add a label to the X-axis\n",
    "plt.xlabel('X Axis Numbers')\n",
    "\n",
    "# Display the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a31eb69-2ead-4d3f-8a6f-d1d55105e1c6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define two lists, 'categories' and 'values'\n",
    "categories = ['group_a', 'group_b', 'group_c']\n",
    "values = [1, 10, 100]\n",
    "\n",
    "# Create a figure with a specific size (12 units wide, 4 units tall)\n",
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "# First subplot: Bar chart\n",
    "plt.subplot(131)\n",
    "plt.bar(categories, values)\n",
    "plt.title('Bar Chart')\n",
    "\n",
    "# Second subplot: Scatter plot\n",
    "plt.subplot(132)\n",
    "plt.scatter(categories, values)\n",
    "plt.title('Scatter Plot')\n",
    "\n",
    "# Third subplot: Line plot\n",
    "plt.subplot(133)\n",
    "plt.plot(categories, values)\n",
    "plt.title('Line Plot')\n",
    "\n",
    "# Add a common title for the entire figure\n",
    "plt.suptitle('Three Different Types of Plots')\n",
    "\n",
    "# Adjust spacing between subplots\n",
    "plt.tight_layout()\n",
    "\n",
    "# Display the subplots\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd184d22-f4f8-4614-b403-7086fdda0c65",
   "metadata": {},
   "source": [
    "![](Seaborn.png)\n",
    "\n",
    "# Seaborn: Fancy visualization with Python\n",
    "\n",
    "Seaborn is a Python data visualization library based on matplotlib. It provides a high-level interface for drawing attractive and informative statistical graphics.\n",
    "\n",
    "[Seaborn Documentation](https://seaborn.pydata.org/tutorial.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79ef5f7d-e752-4b2b-8632-03b74bbe1da5",
   "metadata": {
    "tags": []
   },
   "source": [
    "**Dataset Description:**\n",
    "The dataset used in this visualization is the \"tips\" dataset, which contains information about restaurant bills and tips. It includes details such as the total bill amount, the tip amount, the time of dining (lunch or dinner), whether the diners are smokers or non-smokers, and the size of the dining group.\n",
    "\n",
    "**Graph Description:**\n",
    "This graph is a customized and reduced-size relational plot (relplot) created using Seaborn and Matplotlib. It explores the relationship between the total bill amount and the tip amount, with a focus on different dining times and smoker status.\n",
    "\n",
    "- **Data Points and Markers:** The data points are represented as markers, with two different markers (\"o\" and \"s\") used to distinguish between smokers and non-smokers.\n",
    "\n",
    "- **Colors:** The data points are color-coded based on whether the diners are smokers or non-smokers, using a custom color palette. Blue (\"#007acc\") is used for non-smokers, and orange (\"#ff7f0e\") is used for smokers.\n",
    "\n",
    "- **Subplots:** The graph is organized into separate subplots, one for each combination of dining time (lunch and dinner). This allows for a comparison of tip amounts and total bill amounts between lunch and dinner.\n",
    "\n",
    "- **Legend:** The legend to the right of the graph explains the color and marker associations with smoker status. Non-smokers are represented by blue and smokers by orange. The legend helps viewers understand the meaning behind the colors and markers used in the plot.\n",
    "\n",
    "- **Titles and Labels:** The graph is titled \"Tip Amount vs. Total Bill Amount by Time and Smoker Status,\" providing context for the analysis. Additionally, axis labels are included to clarify the variables being compared (Total Bill Amount on the x-axis and Tip Amount on the y-axis).\n",
    "\n",
    "- **Size Variation:** While not explicitly mentioned in the description, the size of data points can vary based on the \"size\" column in the dataset. This size variation can provide additional insights into the data.\n",
    "\n",
    "- **Custom Theme:** The graph follows a custom theme with a dark background (\"style='darkgrid'\"), enhancing the visual appeal and readability of the plot.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79e01721-6fea-4efc-b51e-edc1d5bbaa24",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define a custom color palette as a list of colors\n",
    "custom_palette = [\"#007acc\", \"#ff7f0e\"]  # Blue and orange colors for differentiating categories\n",
    "\n",
    "# Apply a custom theme with a dark background\n",
    "sns.set_theme(style=\"darkgrid\")  # Sets the background theme with a dark grid\n",
    "\n",
    "# Load the \"tips\" dataset\n",
    "tips = sns.load_dataset(\"tips\")  # Loads dataset containing information about restaurant tips\n",
    "\n",
    "# Create a relplot with enhanced customization and reduced size\n",
    "g = sns.relplot(\n",
    "    data=tips,  # Dataset to use\n",
    "    x=\"total_bill\",  # X-axis represents total bill amount in dollars\n",
    "    y=\"tip\",  # Y-axis represents tip amount in dollars\n",
    "    col=\"time\",  # Creates subplots for different times (e.g., Lunch, Dinner)\n",
    "    hue=\"smoker\",  # Color points by smoker status\n",
    "    style=\"smoker\",  # Change point styles based on smoker status\n",
    "    size=\"size\",  # Point size represents the size of the party\n",
    "    palette=custom_palette,  # Use the custom color palette\n",
    "    aspect=1.0,  # Square aspect ratio for subplots\n",
    "    height=5,  # Height of each subplot\n",
    "    markers=[\"o\", \"s\"],  # Custom markers for smoker categories\n",
    ")\n",
    "\n",
    "# Set titles and labels\n",
    "g.set_axis_labels(\"Total Bill Amount ($)\", \"Tip Amount ($)\")  # Axis labels for x and y\n",
    "g.set_titles(col_template=\"{col_name} Dinner\")  # Title template for subplots\n",
    "\n",
    "# Customize the colorbar label\n",
    "g._legend.set_title(\"Smoker Status\")  # Legend title for smoker status\n",
    "\n",
    "# Set a descriptive title for the entire plot\n",
    "plt.subplots_adjust(top=0.85)  # Adjust subplot layout\n",
    "g.fig.suptitle(\"Tip Amount vs. Total Bill Amount by Time and Smoker Status\")  # Main title\n",
    "\n",
    "# Move the legend outside the plot and adjust its position\n",
    "g._legend.set_bbox_to_anchor((1.05, 0.5))  # Positioning the legend outside the plot\n",
    "g._legend.set_frame_on(False)  # Remove the legend frame\n",
    "\n",
    "# Show the reduced-size plot\n",
    "plt.show()  # Display the plot\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85781f18-43aa-4173-bc3a-9cfef5e948ca",
   "metadata": {},
   "source": [
    "**Dataset Description:**\n",
    "The dataset used in this visualization is the \"dots\" dataset, which contains data related to response times in a psychological experiment. It includes information on response times, alignment, choice, coherence, and firing rates.\n",
    "\n",
    "**Graph Description:**\n",
    "This line plot visualizes the \"dots\" dataset, showing how response times and firing rates vary across different experimental conditions. The plot creates separate line plots for different alignment conditions, with lines colored based on the \"choice\" column. The size of each line varies depending on the \"coherence\" column, and different markers are used to distinguish between different choices. Each subplot represents a unique alignment condition, allowing for a comparison of response times and firing rates. This visualization provides insights into the relationship between response times, firing rates, and experimental factors.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b437d0ba-8412-4ecf-b43e-aa5ac7bc64fb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Import Seaborn library\n",
    "import seaborn as sns\n",
    "\n",
    "# Load the \"dots\" dataset from Seaborn's dataset collection\n",
    "dots = sns.load_dataset(\"dots\")\n",
    "\n",
    "sns.relplot(\n",
    "    data=dots,           # Specify the dataset to use (dots dataset)\n",
    "    kind=\"line\",         # Create a line plot\n",
    "    x=\"time\",            # Set the x-axis data to the \"time\" column\n",
    "    y=\"firing_rate\",     # Set the y-axis data to the \"firing_rate\" column\n",
    "    col=\"align\",         # Create separate columns for each unique value in the \"align\" column\n",
    "    hue=\"choice\",        # Color lines based on the \"choice\" column\n",
    "    size=\"coherence\",    # Vary line size based on the \"coherence\" column\n",
    "    style=\"choice\",      # Distinguish lines using different markers based on the \"choice\" column\n",
    "    facet_kws=dict(sharex=False),  # Do not share x-axes between subplots\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de3cabd6-a815-4806-8c83-f6e3c37d5110",
   "metadata": {},
   "source": [
    "![](Pandas_logo.png)\n",
    "\n",
    "# Matplotlib: Visualization with Python\n",
    "\n",
    "**pandas** is a fast, powerful, flexible and easy to use open source data analysis and manipulation tool,\n",
    "built on top of the Python programming language.\n",
    "\n",
    "[Pandas Documentation](https://pandas.pydata.org/docs/user_guide/index.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5d715c3-d778-444a-8996-cb0ddc579646",
   "metadata": {},
   "source": [
    "## Object creation\n",
    "\n",
    "Creating a Series by passing a list of values, letting pandas create a default integer index:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36304e42-3dd8-4aa9-bb20-014f8533f183",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Creating a pandas Series and printing it\n",
    "\n",
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Create a pandas Series 's'\n",
    "s = pd.Series([1, 3, 5, np.nan, 6, 8])\n",
    "# Explanation:\n",
    "# - pd.Series() is a function from the pandas library used to create a Series.\n",
    "# - A Series is a one-dimensional array-like object capable of holding any data type.\n",
    "# - Here, the Series 's' is created with a list of numbers: 1, 3, 5, np.nan, 6, 8.\n",
    "# - 'np.nan' is a constant from the NumPy library representing 'Not a Number', \n",
    "#   used here to simulate a missing value.\n",
    "\n",
    "print(s)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37226dec-2703-4379-981d-930f54ab0854",
   "metadata": {},
   "source": [
    "**Creating a DataFrame by passing a NumPy array, with a datetime index using date_range() and labeled columns:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "496399d4-15f7-4c00-9cf1-74ff711c3f17",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Creating a DataFrame with date indices and printing it\n",
    "\n",
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Create a range of dates\n",
    "dates = pd.date_range(\"20130101\", periods=6)\n",
    "# Explanation:\n",
    "# - pd.date_range() is used to create a sequence of datetime objects.\n",
    "# - \"20130101\" is the start date (in YYYYMMDD format).\n",
    "# - 'periods=6' defines the number of periods (days in this case) to generate.\n",
    "# - This will create a sequence of 6 dates starting from January 1, 2013.\n",
    "\n",
    "# Print the created dates\n",
    "print(\"These are the dates\")\n",
    "print(\"===================\")\n",
    "print(dates)\n",
    "# Explanation:\n",
    "# - Prints a header followed by the sequence of dates.\n",
    "\n",
    "# Create a DataFrame\n",
    "df = pd.DataFrame(np.random.randn(6, 4), index=dates, columns=list(\"ABCD\"))\n",
    "# Explanation:\n",
    "# - pd.DataFrame() creates a DataFrame, a 2-dimensional labeled data structure.\n",
    "# - np.random.randn(6, 4) generates a 6x4 array of random numbers from a standard normal distribution.\n",
    "# - 'index=dates' sets the index of the DataFrame to the previously created date range.\n",
    "# - 'columns=list(\"ABCD\")' defines the column labels as 'A', 'B', 'C', 'D'.\n",
    "\n",
    "# Print the created DataFrame\n",
    "print(\"\")\n",
    "print(\"This is the DataFrame\")\n",
    "print(\"=====================\")\n",
    "print(df)\n",
    "# Explanation:\n",
    "# - Prints a header followed by the DataFrame.\n",
    "# - The DataFrame 'df' consists of 6 rows and 4 columns, with dates as row indices and 'A', 'B', 'C', 'D' as column headers.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbc28a0c-48b8-4cb6-9f6e-54f1df1eca7c",
   "metadata": {},
   "source": [
    "**Creating a DataFrame by passing a dictionary of objects that can be converted into a series-like structure:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "705fa908-224f-40a1-8252-2a7a1fc43bd8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Creating a more complex DataFrame with mixed data types\n",
    "\n",
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Create a DataFrame 'df2' with specified columns and data types\n",
    "df2 = pd.DataFrame(\n",
    "    {\n",
    "        \"A\": 1.0,  # Column 'A' with a constant float value of 1.0\n",
    "        \"B\": pd.Timestamp(\"20130102\"),  # Column 'B' with a Timestamp\n",
    "        \"C\": pd.Series(1, index=list(range(4)), dtype=\"float32\"),  # Column 'C' with a Series of floats\n",
    "        \"D\": np.array([3] * 4, dtype=\"int32\"),  # Column 'D' with an array of integers\n",
    "        \"E\": pd.Categorical([\"test\", \"train\", \"test\", \"train\"]),  # Column 'E' with categorical data\n",
    "        \"F\": \"foo\",  # Column 'F' with a constant string value 'foo'\n",
    "    }\n",
    ")\n",
    "# Explanation:\n",
    "# - 'A': All entries in this column are set to 1.0 (float).\n",
    "# - 'B': All entries in this column are set to January 2, 2013 (datetime object).\n",
    "# - 'C': A pandas Series with four entries, all set to 1.0 (float32). \n",
    "# - 'D': A NumPy array with four entries, all set to 3 (int32).\n",
    "# - 'E': A pandas Categorical data type with two distinct categories ('test' and 'train').\n",
    "# - 'F': A column with the string 'foo' in all rows.\n",
    "\n",
    "# Print the created DataFrame 'df2'\n",
    "print(df2)\n",
    "# Explanation:\n",
    "# - This prints the DataFrame 'df2' to the console.\n",
    "# - The DataFrame consists of 4 rows and 6 columns, each with different data types.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c757bce9-7405-4c3e-aa0a-a8d489f2c9d1",
   "metadata": {},
   "source": [
    "**The columns of the resulting DataFrame have different dtypes:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81c59557-6cba-4b58-80f4-cfcd15d72848",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the data types of each column in the DataFrame 'df2'\n",
    "df2.dtypes\n",
    "# Explanation:\n",
    "# - 'df2' refers to the DataFrame created earlier.\n",
    "# - '.dtypes' is an attribute of the DataFrame that returns a Series showing the data type of each column."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb3a2b30-f528-4896-828d-e24285b87937",
   "metadata": {},
   "source": [
    "## Viewing data\n",
    "\n",
    "Use DataFrame.head() and DataFrame.tail() to view the top and bottom rows of the frame respectively:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90cbc82f-5d2a-4689-b59a-1d8609f8f79f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Displaying the first few rows of the DataFrame 'df'\n",
    "\n",
    "df.head()\n",
    "# Explanation:\n",
    "# - 'df' refers to a previously created DataFrame.\n",
    "# - '.head()' is a method of the DataFrame that returns the first five rows.\n",
    "# - This method is particularly useful for getting a quick snapshot of the DataFrame,\n",
    "#   especially when dealing with large datasets. It helps in understanding the data's structure,\n",
    "#   format, and a few entries without the need to display the entire DataFrame.\n",
    "# - By default, 'df.head()' displays the first five rows, but you can specify a different\n",
    "#   number by passing an integer as an argument, like 'df.head(n)' where 'n' is the number of rows to display.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8888370c-b981-4b98-8ad6-9b36222ec354",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Displaying the last few rows of the DataFrame 'df'\n",
    "\n",
    "df.tail()\n",
    "# Explanation:\n",
    "# - 'df' refers to a previously created DataFrame.\n",
    "# - '.tail()' is a method of the DataFrame that returns the last five rows.\n",
    "# - This method is useful for quickly viewing the end of a dataset, especially in cases\n",
    "#   where you want to verify recent data entries or the tail-end structure of the data.\n",
    "# - Similar to 'df.head()', 'df.tail()' displays the last five rows by default. However, \n",
    "#   you can specify a different number of rows by passing an integer, like 'df.tail(n)',\n",
    "#   where 'n' is the desired number of rows to display from the end of the DataFrame.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00ffd1d4-a3c4-478a-b48f-a712bd9bbe09",
   "metadata": {},
   "source": [
    "![](scikit-learn_logo.png)\n",
    "\n",
    "# scikit-learn: Machine Learning Libraries and More\n",
    "\n",
    "Simple and efficient tools for predictive data analysis\n",
    "Accessible to everybody, and reusable in various contexts\n",
    "\n",
    "[scikit-learn Documentation](https://scikit-learn.org/stable/user_guide.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dccd5c09-4bbb-46f7-b3bc-d5f654b08fcc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Import the packages needed for data manipulation, analysis, and visualization\n",
    "\n",
    "# Importing numpy as np\n",
    "import numpy as np\n",
    "# Explanation:\n",
    "# - NumPy (Numerical Python) is a fundamental package for scientific computing in Python.\n",
    "# - It provides support for large, multi-dimensional arrays and matrices, along with a \n",
    "#   large collection of high-level mathematical functions to operate on these arrays.\n",
    "# - The alias 'np' is commonly used for NumPy, allowing for concise code.\n",
    "\n",
    "# Importing pandas as pd\n",
    "import pandas as pd\n",
    "# Explanation:\n",
    "# - pandas is an open-source data analysis and manipulation tool, built on top of Python.\n",
    "# - It offers data structures like DataFrames and Series for handling and analyzing structured data.\n",
    "# - The alias 'pd' is standard for pandas, facilitating brief and readable code.\n",
    "\n",
    "# Importing matplotlib.pyplot as plt\n",
    "import matplotlib.pyplot as plt\n",
    "# Explanation:\n",
    "# - Matplotlib is a comprehensive library for creating static, animated, and interactive visualizations in Python.\n",
    "# - The 'pyplot' module in Matplotlib provides a MATLAB-like interface for plotting.\n",
    "# - The alias 'plt' is conventionally used for this module, simplifying access to plotting functions.\n",
    "\n",
    "# Importing seaborn as sns\n",
    "import seaborn as sns\n",
    "# Explanation:\n",
    "# - Seaborn is a Python data visualization library based on Matplotlib.\n",
    "# - It provides a high-level interface for drawing attractive and informative statistical graphics.\n",
    "# - The alias 'sns' is typically used for Seaborn, making it more straightforward to use its functions.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeff754e-331a-4557-9fe9-82a4799d5903",
   "metadata": {},
   "source": [
    "# Diabetes Dataset\n",
    "This dataset is originally from the N. Inst. of Diabetes & Diges. & Kidney Dis.\n",
    "\n",
    "\n",
    "## About Dataset\n",
    "\n",
    "### Context\n",
    "This dataset is originally from the National Institute of Diabetes and Digestive and Kidney Diseases. The objective is to predict based on diagnostic measurements whether a patient has diabetes.\n",
    "\n",
    "### Content\n",
    "Several constraints were placed on the selection of these instances from a larger database. In particular, all patients here are females at least 21 years old of Pima Indian heritage.\n",
    "\n",
    "* Pregnancies: Number of times pregnant\n",
    "* Glucose: Plasma glucose concentration a 2 hours in an oral glucose tolerance test\n",
    "* BloodPressure: Diastolic blood pressure (mm Hg)\n",
    "* SkinThickness: Triceps skin fold thickness (mm)\n",
    "* Insulin: 2-Hour serum insulin (mu U/ml)\n",
    "* BMI: Body mass index (weight in kg/(height in m)^2)\n",
    "* DiabetesPedigreeFunction: Diabetes pedigree function\n",
    "* Age: Age (years)\n",
    "* Outcome: Class variable (0 or 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04a22cfd-5ad7-470b-a3a3-a9cf7222df1c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Loading a dataset into a pandas DataFrame\n",
    "\n",
    "# Importing pandas library\n",
    "import pandas as pd\n",
    "\n",
    "# Load the dataset from a CSV file into a DataFrame\n",
    "data = pd.read_csv('diabetes.csv')\n",
    "# Explanation:\n",
    "# - 'pd.read_csv()' is a function in the pandas library used to read a CSV (Comma-Separated Values) file into a DataFrame.\n",
    "# - 'diabetes.csv' is the name of the file containing the dataset. This file should be located in the current working directory,\n",
    "#   or you should provide the full path to the file.\n",
    "# - The resulting DataFrame, 'data', contains the data from the 'diabetes|.csv' file.\n",
    "# - This is a common method for importing structured data into Python for analysis and manipulation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b91ab574-57c7-4420-8b18-2a8a087090bc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Viewing the first few rows of the DataFrame 'data'\n",
    "\n",
    "# Use the 'head()' method on the DataFrame\n",
    "data.head()\n",
    "# Explanation:\n",
    "# - 'data' refers to the DataFrame created by loading data from the 'diabetes2.csv' file.\n",
    "# - '.head()' is a method in pandas used to quickly view the first few rows of a DataFrame.\n",
    "# - By default, 'data.head()' displays the first five rows of the DataFrame.\n",
    "# - This is particularly useful for getting an initial understanding of the data's structure,\n",
    "#   such as the column names, data types, and a glimpse of the first few entries.\n",
    "# - It helps in determining if the data has been loaded correctly and gives an insight into what kind of data analysis or \n",
    "#   manipulation might be required.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "426f9343-5741-4118-afc1-027352940bc2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Examining the detailed information of the DataFrame 'data'\n",
    "\n",
    "# Use the 'info()' method on the DataFrame\n",
    "data.info()\n",
    "# Explanation:\n",
    "# - 'data' is the DataFrame which was created from the 'diabetes2.csv' file.\n",
    "# - '.info()' is a method in pandas that provides a concise summary of the DataFrame.\n",
    "# - This method displays information such as the number of entries, the total number of columns,\n",
    "#   the data type of each column, the number of non-null entries in each column, and the memory usage.\n",
    "# - Using 'data.info()' is beneficial for understanding the structure of the DataFrame at a glance.\n",
    "# - It helps in identifying if there are any missing values in the dataset and the data types of each column,\n",
    "#   which is crucial for data preprocessing and analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adbc78f8-3f38-423b-b58c-4194801bd82e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Describe the DataFrame\n",
    "# This line uses the describe() method from pandas to generate descriptive statistics of the DataFrame 'data'.\n",
    "# It provides a summary that includes count, mean, standard deviation, min, max, and percentile values for each column.\n",
    "# This is useful for gaining insights into the dataset, such as understanding data distribution, identifying outliers, and preliminary data analysis.\n",
    "data.describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43e53ada-22a5-45c7-a159-298114ed7400",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Analyzing Correlations in the DataFrame\n",
    "# This line uses the corr() method from pandas to calculate the correlation coefficients for the pairwise relationships between the columns in the DataFrame 'data'.\n",
    "# The method returns a correlation matrix that provides insights into the strength and direction of the relationships between variables.\n",
    "# This is valuable for identifying potential connections between variables, which can inform further analysis and feature selection for modeling.\n",
    "data.corr()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa2c1947-ac5a-433f-b70b-871e282355be",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Creating a Heatmap for the Correlation Matrix\n",
    "# First, we create a figure and an axis using plt.subplots, setting the size of the figure to 9x9 inches.\n",
    "fig, ax = plt.subplots(figsize=(9,9))\n",
    "\n",
    "# Then, we use the imshow function of the axis object to create a heatmap. The heatmap represents the correlation matrix calculated by data.corr().\n",
    "# 'interpolation='nearest'' ensures that the displayed image has sharp boundaries between different values.\n",
    "im = ax.imshow(data.corr(), interpolation='nearest')\n",
    "\n",
    "# Finally, we add a colorbar to the figure, orienting it vertically. This colorbar provides a reference scale for interpreting the heatmap colors.\n",
    "fig.colorbar(im, orientation='vertical')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50b18811-0bb0-47de-84d7-7e78c2da146c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Generating a Heatmap with Seaborn\n",
    "# First, we set up a Matplotlib figure and axis with a specified size (8x6 inches) for the heatmap.\n",
    "f, ax = plt.subplots(figsize=(8,6))\n",
    "\n",
    "# We then use Seaborn's heatmap function to visualize the correlation matrix of 'data'.\n",
    "# 'cmap=\"GnBu\"' sets the color scheme to Green-Blue shades, providing a visual gradient for the correlations.\n",
    "# 'annot=True' enables annotations within the heatmap, displaying the correlation values.\n",
    "# 'linewidths=0.5' adds lines between the cells in the heatmap for better visual separation.\n",
    "# 'fmt='.1f'' formats the annotation to one decimal place.\n",
    "# 'ax=ax' specifies that the heatmap is to be drawn on the predefined Matplotlib axis.\n",
    "sns.heatmap(data.corr(), cmap=\"GnBu\", annot=True, linewidths=0.5, fmt='.1f', ax=ax)\n",
    "\n",
    "# Finally, plt.show() displays the figure with the heatmap.\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da841d13-633f-4fbb-ad10-012e56a9a5aa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Sorting Correlation Values\n",
    "# This line is focused on sorting the correlation values in relation to the 'Outcome' column in the DataFrame 'data'.\n",
    "# First, the corr() method is called on 'data' to compute the pairwise correlation of all columns.\n",
    "# Then, '.Outcome' accesses the correlation values specific to the 'Outcome' column.\n",
    "# Finally, sort_values() is applied to these correlation values to sort them in ascending order.\n",
    "# This can help in understanding how different features correlate with the 'Outcome' column, identifying strong or weak relationships.\n",
    "data.corr().Outcome.sort_values()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a05b8bc3-6d9d-4974-be90-73227b2bba1d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Separating the Target Variable from Features\n",
    "# The target variable, 'Outcome', is extracted from the DataFrame 'data' and stored in 'y'.\n",
    "# This is achieved using the .loc method to access the 'Outcome' column and the .values to get its values as an array.\n",
    "y = data.loc[:,\"Outcome\"].values\n",
    "\n",
    "# Next, the 'Outcome' column is dropped from 'data' to create a new DataFrame 'x' containing only the features.\n",
    "# This is done using the .drop() method, specifying the column to be dropped and setting 'axis=1' to indicate column-wise operation.\n",
    "# The resulting 'x' DataFrame contains all columns from 'data' except the 'Outcome' column.\n",
    "x = data.drop(['Outcome'], axis = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94c69f04-13cd-4b58-86bd-cef6d4f9cb5a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Splitting Data into Training and Testing Sets\n",
    "# Importing the train_test_split function from sklearn.model_selection module for splitting data arrays into two subsets: training and testing.\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# The train_test_split function is then used to split the features (x) and the target variable (y) into training and testing sets.\n",
    "# 'test_size = 0.33' specifies that 33% of the data will be reserved for the test set, and the remaining 67% for the training set.\n",
    "# 'random_state = 123' is used for reproducibility, ensuring that the same split occurs every time the script is run.\n",
    "# This results in four arrays: x_train and y_train for training data, and x_test and y_test for testing data.\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.33, random_state = 123)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84f04e39-0079-4c7d-8d62-e5cf9b73a340",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Importing the linear_model module from the scikit-learn library\n",
    "from sklearn import linear_model\n",
    "\n",
    "# Creating a logistic regression object\n",
    "# Setting 'max_iter' to 150, which is the number of iterations taken for the solvers to converge\n",
    "logreg = linear_model.LogisticRegression(max_iter=150)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5914d375-d15c-4465-9f0f-ba8b5dff68fd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Training the Logistic Regression Model\n",
    "# This line of code is used to fit, or train, the logistic regression model on the training dataset.\n",
    "# The 'fit' method takes two arguments: 'x_train' and 'y_train'.\n",
    "# 'x_train' contains the feature data for training - this is the data the model learns from.\n",
    "# 'y_train' contains the corresponding target labels for the training data.\n",
    "# By calling 'logreg.fit(x_train, y_train)', the logistic regression model 'logreg' learns from the training data \n",
    "# and tries to find the best parameters that can be used to predict the outcomes based on the features.\n",
    "logreg.fit(x_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2f03114-a1e1-46cd-bd70-89cb170e7c35",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Making Predictions with the Logistic Regression Model\n",
    "# This line of code utilizes the 'predict' method of the logistic regression model 'logreg' to make predictions.\n",
    "# The method takes one argument: 'x_test', which contains the feature data of the testing set.\n",
    "# 'x_test' is the unseen data that the model has not been trained on, and it's used to evaluate the model's performance.\n",
    "# The 'predict' method uses the model, which has been trained on 'x_train' and 'y_train', to predict the outcomes for 'x_test'.\n",
    "# The predictions are stored in the variable 'predicted'.\n",
    "# These predictions can then be compared against the actual labels 'y_test' to assess the model's accuracy.\n",
    "predicted = logreg.predict(x_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb1cbccf-c073-419c-87ed-74f4112a67e7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Displaying the Accuracy of the Logistic Regression Model\n",
    "# This line of code is used to calculate and print the accuracy of the logistic regression model 'logreg' on the test dataset.\n",
    "# The 'score' method of the logistic regression model takes two arguments: 'x_test' and 'y_test'.\n",
    "# 'x_test' contains the feature data of the testing set, and 'y_test' contains the corresponding actual labels.\n",
    "# The 'score' method compares the predicted labels (generated by the model for 'x_test') against the actual labels 'y_test'.\n",
    "# It returns the accuracy of the model, which is the proportion of correct predictions out of the total number of predictions.\n",
    "# The accuracy is then formatted into a string and printed out. This provides a quick and straightforward assessment \n",
    "# of how well the model is performing, with higher accuracy indicating better performance.\n",
    "print(\"Test accuracy: {} \".format(logreg.score(x_test, y_test)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "500d55be-eb75-48a3-854f-f47aa8b09ce7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Creating a Confusion Matrix to Evaluate Model Performance\n",
    "# This section of code utilizes the 'confusion_matrix' function from 'sklearn.metrics'.\n",
    "# A confusion matrix is a table that is used to evaluate the performance of a classification model.\n",
    "# It compares the predicted labels ('predicted') with the actual labels ('y_test') from the testing dataset.\n",
    "# The resulting 'cf_matrix' is a 2x2 matrix that provides the counts of True Positives (TP), True Negatives (TN),\n",
    "# False Positives (FP), and False Negatives (FN).\n",
    "# These values are essential for assessing the model's ability to correctly classify instances into different classes.\n",
    "cf_matrix = confusion_matrix(y_test, predicted)\n",
    "cf_matrix\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab048cea-89b6-4b3d-a4c8-f4eec4bb55e5",
   "metadata": {},
   "source": [
    "* True Positives (TP): 139\n",
    "\n",
    "    * These are cases where the model correctly predicted the positive class (e.g., a disease is present), and it was indeed present in the actual data.\n",
    "* False Positives (FP): 18\n",
    "\n",
    "    * These are cases where the model incorrectly predicted the positive class (e.g., a disease is present), but it was not actually present in the actual data. In other words, the model made a false alarm.\n",
    "\n",
    "* False Negatives (FN): 35\n",
    "\n",
    "    * These are cases where the model incorrectly predicted the negative class (e.g., a disease is not present), but it was actually present in the actual data. This represents a missed opportunity to detect the positive class.\n",
    "\n",
    "* True Negatives (TN): 62\n",
    "\n",
    "    * These are cases where the model correctly predicted the negative class (e.g., a disease is not present), and it was indeed not present in the actual data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71705caa-6cc7-4273-8138-08a668e44675",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Creating a Heatmap of the Confusion Matrix\n",
    "# This code uses the 'sns.heatmap' function from the Seaborn library to visualize the confusion matrix 'cf_matrix'.\n",
    "# The values in 'cf_matrix' are normalized to show proportions and percentages.\n",
    "# 'annot=True' adds the actual values to each cell of the heatmap.\n",
    "# 'fmt='.2%' formats the annotations to display percentages with two decimal places.\n",
    "# 'cmap='Blues'' sets the color map for the heatmap to a blue gradient.\n",
    "# The resulting heatmap provides a visual representation of the model's classification performance.\n",
    "sns.heatmap(cf_matrix/np.sum(cf_matrix), annot=True, fmt='.2%', cmap='Blues')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7f5f826-6b21-4f11-9983-0811f4be83c8",
   "metadata": {},
   "source": [
    "![](Confusion_Matrix.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df58dd7c-8967-480c-a96e-575f51a13473",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Creating a Custom DataFrame and Making Specific Predictions\n",
    "# This code creates a custom DataFrame 'test_prediciton_df' with specified column names.\n",
    "# The DataFrame contains two rows of data, each representing a set of features for prediction.\n",
    "# The column names correspond to features like \"Pregnancies,\" \"Glucose,\" etc.\n",
    "# These features are used to make predictions with the trained logistic regression model.\n",
    "column_names = [\"Pregnancies\", \"Glucose\", \"BloodPressure\", \"SkinThickness\", \"Insulin\", \"BMI\", \"DiabetesPedigreeFunction\", \"Age\"]\n",
    "test_prediction_array = [\n",
    "    [6, 148, 72, 35, 0, 33.6, 0.627, 50],\n",
    "    [1, 85, 66, 29, 0, 26.6, 0.351, 31]\n",
    "]\n",
    "test_prediciton_df = pd.DataFrame(test_prediction_array, columns=column_names)\n",
    "\n",
    "# The resulting 'test_prediciton_df' DataFrame is used to make specific predictions.\n",
    "test_prediciton_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20242904-0bd8-4add-90a6-be8c5e3b1d6e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Making Predictions Using the Logistic Regression Model\n",
    "# This line of code uses the trained logistic regression model 'logreg' to make predictions on a custom DataFrame 'test_prediciton_df'.\n",
    "# 'test_prediciton_df' contains feature values for which predictions are needed.\n",
    "# The 'predict' method of the model is called with 'test_prediciton_df' as the argument.\n",
    "# This results in predictions for each set of features in the DataFrame, indicating the model's classification decisions.\n",
    "logreg.predict(test_prediciton_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aa9410e-4f7d-453e-ae67-2ee253b488e2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
